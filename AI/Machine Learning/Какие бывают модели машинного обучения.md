---
tags:
  - MachineLearning
title: Какие бывают модели машинного обучения
create: 2024-04-13
id: 6
location: Machine Learning
link: "[[Machine Learning]]"
---
Рассмотрим примеры моделей машинного обучения с учителем. Каждую из них можно использовать для разных целей — то есть одну и ту же задачу можно решить разными способами.

## Линейная регрессия (регрессионная модель)

Показывает связь нескольких переменных ― как результат `Y` будет зависеть от одной или нескольких переменных `х`. Работает, если между параметрами и результатом наблюдается линейная связь.

Вернёмся к примеру с продавцом мороженого. Есть три переменных: количество проданного товара, день недели и температура воздуха. Исходя из этих данных с помощью регрессионной модели можно спрогнозировать, сколько мороженого закупать у поставщика на следующую неделю.

![[Pasted image 20240413224944.png|400]]
*Линейная регрессия показывает, как результат будет зависеть от переменных, между которыми есть линейная связь*

## Логистическая регрессия (модель классификации)

Показывает взаимосвязь переменных и её результат в линейной зависимости. В отличие от линейной регрессии, зависимая переменная имеет только два значения, например — да / нет или 1 / 0.

Когда пациент звонит в колл-центр клиники, автоответчик называет ему цифры и условия, которые им соответствуют: 1 — стоматология, 2 — детское отделение, 3 — взрослое отделение, 4 — консультация оператора. Если пациент нажимает кнопку «2», ему дают новый выбор: 1 — записаться на консультацию, 2 — получить справку, 3 — отменить приём, и так далее до тех пор, пока клиент не получит желаемый результат.

## Регрессионно-классификационные модели

- **Дерево решений.** В этой модели принятие решений зависит от «узлов» и «листьев». На вершине дерева решений — начальный узел, в него попадает вся выборка. Затем она проверяется на выполнение условия или наличие признака. И так до тех пор, пока не будет получен результат.  
  
Эту модель используют, например, в банке, чтобы решить, одобрить кредит или нет. Если возраст клиента — менее 21 года, алгоритм выдаёт значение «нет». Если возраст 21 год и больше, алгоритм выдаёт значение «да» и отправляет к следующему параметру — уровень дохода и так далее.

- **Модель случайного леса.** Более усовершенствованная версия модели «Дерево решений» — ей реже нужна перенастройка. Состоит из нескольких деревьев решений, связанных между собой.  
  
Модель можно использовать для анализа данных о здоровье пациентов и факторов, которые могут влиять на заболеваемость: возраст, вес, пол. Она будет строить несколько деревьев решений, каждое из которых будет определять важность конкретного фактора в предсказании заболеваемости.

![[Pasted image 20240413230348.png]]
*Множество деревьев решений связываются между собой и создают «случайный лес»*

- **Наивный байесовский классификатор.** Основана на теореме Бейса. Помогает понять, каким будет событие X, если наступит связанное с ним событие Y. В классификации Бейса X — это класс объекта, Y — его признак. Недостаток модели в её предположении, что объекты условно независимы: в реальности это может быть не так.  
  
Чтобы определить, какие из электронных писем мошеннические, а какие — нет, регрессионная модель анализирует письмо, выводит два результата — «спам» или «не спам», и сортирует письма по соответствующим папкам.

- **K-Ближайшие соседи.** Популярная и простая в использовании модель, которая, правда, плохо работает с большими объемами данных. Суть её в том, что объекту моделирования присваивают свойства тех объектов, которые соседствуют с ним и свойства которых уже известны.  
  
При наличии базы данных о предпочтениях пользователей в интернет-магазине можно использовать модель «K-Ближайшие соседи» для предсказания, какой товар может заинтересовать конкретного покупателя. Модель будет искать пользователей с похожими предпочтениями и рекомендовать товары, которые им понравились.

- **AdaBoost.** В процессе обучения выстраивает композицию из базовых алгоритмов для улучшения их эффективности. Суть в том, что каждый следующий классификатор строится по объектам, которые плохо классифицируются предыдущими.  
  
Так создают систему распознавания лиц: AdaBoost спроектирует несколько классификаторов, обученных на данных, содержащих изображения лиц. Каждый классификатор будет стремиться улучшить точность предсказаний предыдущего классификатора.

- **XGBoost.** Строится в форме ансамбля слабых предсказывающих моделей: с каждым новым этапом обучения она вычисляет отклонения предсказаний уже обученного ансамбля. Следующая итерация, которая будет добавлена в ансамбль, будет предсказывать эти отклонения.  
  
Модель можно использовать для работы с финансовыми данными и анализа фундаментальных данных компаний, таких как доходы, расходы, рентабельность.

>**Ансамбль** — согласованность, единство частей, образующих что-либо целое. Например, комплект одежды из нескольких предметов; несколько зданий, выдержанных в едином стиле.

- **Метод опорных векторов.** Подходит для решения задач классификации и регрессии (отношений между переменными). Для этого строится гиперплоскость, которая разделяет объекты выборки оптимальным способом. Чем больше расстояние между разделяющей гиперплоскостью и объектами, тем меньше будет средняя ошибка классификатора.  
  
Например, классификация изображений мозга на основе МРТ-сканов. Метод может быть обучен на большом количестве признаков (размеры опухоли, форма и текстура ткани) и использоваться для разделения изображений на две категории: здоровые и больные.

- **Искусственные нейронные сети.** Имитирует работу человеческого мозга: состоит из слоёв взаимосвязанных узлов (нейронов), которые могут сами учиться сопоставлять входные данные с выходными с помощью процесса.  
  
Например, голосовой помощник Алиса в Яндекс Станции с помощью нейронных сетей учится отвечать на вопросы и поддерживать разговор с пользователем.

