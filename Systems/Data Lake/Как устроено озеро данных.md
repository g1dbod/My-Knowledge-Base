---
tags:
  - DataLake
title: Как устроено озеро данных
create: 2024-04-14
id: 3
location: DataLake
link: "[[Data Lake]]"
---

Озеро представляет собой файловое хранилище на нескольких серверах, в котором лежат данные. Как правило данные распределены между серверами, чтобы хранилище можно было быстро масштабировать — подключить новые серверы для расширения места.  
  
К серверам настраивают подключение разных источников данных, доступных компании. Каналы поставки данных называют пайплайнами, а всю схему подключения — [ETL-процессом](https://practicum.yandex.ru/blog/chto-takoe-etl/). Обычно всё настроено так, чтобы данные загружались автоматически.  
  
Хотя Data Lake и неструктурированное, порядок в нём всё-таки должен быть, иначе спустя время накопится огромное количество данных, в которых невозможно будет разобраться. Поэтому перед добавлением в озеро данные размечают и запоминают, откуда и в каком формате они поступили.  
  
В итоге внутри озера данных хранятся не только сами объекты, но и метаданные, то есть информация об объектах. Это облегчает поиск, извлечение и анализ данных в будущем.  
  
В архитектуре озера данных должны быть предусмотрены инструменты резервного копирования, чтобы информация не терялась.

![[Pasted image 20240414002155.png]]
*Внутри озера данных схема хранения может быть такой. Но это не обязательно — каждый организует свое озеро сам, в зависимости от потребностей бизнеса*

Озеро данных не существует само по себе. К нему примыкают другие инструменты:  
  
- Источники, в которых данные генерируются и собираются. Это могут быть базы данных, CRM, ERP, [[IoT]] и другие системы и сервисы.  
- Аналитические сервисы, которые отбирают, сортируют и анализируют информацию. Например, это BI-инструменты для построения дашбордов. Или сервисы машинного обучения для создания ML-моделей и нейросетей.  
- Хранилища, в которых лежат уже структурированные и очищенные данные из озера.  
  
[Аналитики данных](https://practicum.yandex.ru/blog/professiya-analitik-dannyh/) взаимодействуют именно с инструментами, а не с Data Lake напрямую. Современные озёра данных, как правило, строят с помощью [инструмента Hadoop](https://practicum.yandex.ru/blog/gde-i-zachem-ispolzuetsya-hadoop/). Он позволяет хранить поступающую информацию на разных подсерверах и обрабатывает её параллельно, что значительно ускоряет работу.

![[Pasted image 20240414002520.png]]
*Схематично структура хранения выглядит так. При загрузке файлы равномерно распределяются по разным серверам, и затем запрос на выгрузку обрабатывается на каждом сервере параллельно. Это позволяет выполнить его в несколько раз быстрее, чем если бы все данные выгружались с одного сервера*

